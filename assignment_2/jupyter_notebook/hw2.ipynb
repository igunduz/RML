{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FKZDMi_5iKCA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.colors import LightSource\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A0EQP5iN5L",
        "outputId": "ee2fb2d9-43b0-4650-b07e-05755d75ceac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# download MNIST training and testing datasets, then prepare corresponding dataloaders (batch size = 100)\n",
        "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PjUrtvq_iUbQ"
      },
      "outputs": [],
      "source": [
        "# initialize the CNN architecture with 4 convolutional layers and 2 MLP layers for standard training\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "model_cnn = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M_cv5SjtiWZE"
      },
      "outputs": [],
      "source": [
        "#### Your task: complete the following function\n",
        "def pgd(model, X, y, epsilon=0.1, alpha=0.02, num_iter=10, randomize=False):\n",
        "    \"\"\" Construct PGD adversarial examples for the example (X,y)\"\"\"\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "    for t in range(num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return X + delta.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N6yvOm8ciZUL"
      },
      "outputs": [],
      "source": [
        "#### Your task: complete the following functions\n",
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item()*X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "def epoch_adv(loader, model, attack, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y, **kwargs)\n",
        "        yp = model(X+delta)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item()*X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDwITEWRiaxv",
        "outputId": "9025c132-fc70-4df8-f630-42394a9ca2b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.077267\t0.024500\t0.167800\n",
            "0.023183\t0.020100\t0.165800\n",
            "0.015283\t0.015900\t0.170900\n",
            "0.011700\t0.013000\t0.150100\n",
            "0.009383\t0.014600\t0.179300\n"
          ]
        }
      ],
      "source": [
        "# specify the optimizer as SGD\n",
        "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
        "\n",
        "# standard training\n",
        "for t in range(5):\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
        "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn, pgd)\n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "\n",
        "# save the standard trained model for further evaluation\n",
        "torch.save(model_cnn.state_dict(), \"model_cnn.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4Dht-vSxlloO"
      },
      "outputs": [],
      "source": [
        "# use the same CNN architecture for robust training\n",
        "model_cnn_robust = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 Flatten(),\n",
        "                                 nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                                 nn.Linear(100, 10)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KKsmaBalooX",
        "outputId": "504c3da5-dcf7-455d-9808-bc21e3b8bc91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.219083\t0.022200\t0.044700\n"
          ]
        }
      ],
      "source": [
        "# specify the optimizer as SGD\n",
        "opt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "\n",
        "# PGD-based adversarial training\n",
        "for t in range(5):\n",
        "    train_err, train_loss = epoch_adv(train_loader, model_cnn_robust, pgd, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
        "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn_robust, pgd)\n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "\n",
        "# save the standard trained model for further evaluation\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fT5MZujiN9Da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the standard trained and adversarially trained models\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn.pt\"))\n",
        "model_cnn_robust.load_state_dict(torch.load(\"model_cnn_robust.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f48ELj_UN-uI"
      },
      "outputs": [],
      "source": [
        "def fgsm(model, X, y, epsilon=0.1):\n",
        "    \"\"\" Construct FGSM adversarial examples for the example (X,y)\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "    loss.backward()\n",
        "    return epsilon * delta.grad.detach().sign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ecDX3ziXPibw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clean: 0.0128 0.0096\n",
            "FGSM:  0.5438 0.0490\n",
            "PGD (10 iter): 0.1737 0.0225\n"
          ]
        }
      ],
      "source": [
        "# clean performance (no attack)\n",
        "print(\"clean:\", \"{:.4f}\".format(epoch(test_loader, model_cnn)[0]),\n",
        "      \"{:.4f}\".format(epoch(test_loader, model_cnn_robust)[0]))\n",
        "\n",
        "# evaluate both models using FGSM attack\n",
        "print(\"FGSM: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, fgsm)[0]),\n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, fgsm)[0]))\n",
        "\n",
        "# evaluate both models using PGD attack\n",
        "print(\"PGD (10 iter):\", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, pgd, num_iter=10)[0]),\n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, pgd, num_iter=10)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-EfxdKahQL3v"
      },
      "outputs": [],
      "source": [
        "#### Your task (bonus): develop an attack method to achieve an attack success rate as high as possible. You can modify the following function if needed.\n",
        "\n",
        "# You can try out some of the attack methods introduced in Lectures 3-4 or develop your unique creative attack.\n",
        "# In principle, the performance of your attack should be better than FGSM or PGD, 10 iter;\n",
        "# The higher attack success rates you can achieve, the higher credits you may receive.\n",
        "\n",
        "def my_attack(model, X, y, epsilon=0.1):\n",
        "  \"\"\" Construct adversarial examples for the example (X,y)\"\"\"\n",
        "  delta = torch.zeros_like(X, requires_grad=True)\n",
        "  alpha = epsilon/5 # initial step size was epsilon/10 and gave 0.1656 0.0223\n",
        "  for _ in range(10):\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "    loss.backward()\n",
        "    delta.data += alpha * delta.grad.detach().sign()\n",
        "    delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
        "    delta.grad.zero_()\n",
        "  return X + delta.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aQVHww4GRwn6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Attack:  0.1737 0.0225\n"
          ]
        }
      ],
      "source": [
        "print(\"My Attack: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, my_attack)[0]), \n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, my_attack)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Attack:  0.0186 0.0117\n"
          ]
        }
      ],
      "source": [
        "# Tried a version of zoo attack\n",
        "# Changed epsilon to 0.2 and alpha to 0.05\n",
        "def my_attack(model, X, y, epsilon=0.2, alpha=0.05, num_iterations=10):\n",
        "    \"\"\" Construct adversarial examples on the examples X\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=False)\n",
        "    for i in range(num_iterations):\n",
        "        for j in range(X.shape[1]):\n",
        "            delta_j = torch.zeros_like(X)\n",
        "            delta_j[:, j, :, :] = alpha\n",
        "            loss_plus = nn.CrossEntropyLoss()(model(X + delta + delta_j), y)\n",
        "            loss_minus = nn.CrossEntropyLoss()(model(X + delta - delta_j), y)\n",
        "            grad_approx = (loss_plus - loss_minus) / (2 * alpha)\n",
        "            delta[:, j, :, :] += alpha * torch.sign(grad_approx)\n",
        "        delta = torch.clamp(delta, -epsilon, epsilon)\n",
        "    return delta\n",
        "\n",
        "\n",
        "print(\"My Attack: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, my_attack)[0]), \n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, my_attack)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My Attack:  0.0185 0.0117\n"
          ]
        }
      ],
      "source": [
        "# Changed epsilon to 0.2 and alpha to 0.1\n",
        "def my_attack(model, X, y, epsilon=0.2, alpha=0.1, num_iterations=10):\n",
        "    \"\"\" Construct adversarial examples on the examples X\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=False)\n",
        "    for i in range(num_iterations):\n",
        "        for j in range(X.shape[1]):\n",
        "            delta_j = torch.zeros_like(X)\n",
        "            delta_j[:, j, :, :] = alpha\n",
        "            loss_plus = nn.CrossEntropyLoss()(model(X + delta + delta_j), y)\n",
        "            loss_minus = nn.CrossEntropyLoss()(model(X + delta - delta_j), y)\n",
        "            grad_approx = (loss_plus - loss_minus) / (2 * alpha)\n",
        "            delta[:, j, :, :] += alpha * torch.sign(grad_approx)\n",
        "        delta = torch.clamp(delta, -epsilon, epsilon)\n",
        "    return delta\n",
        "\n",
        "\n",
        "print(\"My Attack: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, my_attack)[0]), \n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, my_attack)[0]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
